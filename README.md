# Reading

This is the cumulative sum of my notes from absolute basics to SOTA methods for ML. Just to keep track of what I'm learning.

## Sources
- Basics
    - [LLM Series](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
    - [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
    - [Attention? Attention!](https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html)
- [Stanford CME 295 LLMS](https://cme295.stanford.edu/syllabus/)
- [Primer on the inner workings of transformer-based language models](https://arxiv.org/pdf/2502.17516)
- [Large Language Models: A Survey](https://arxiv.org/pdf/2402.06196v2)
